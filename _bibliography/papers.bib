---
---
@inproceedings{meade-etal-2022-empirical,
    title = "An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models",
    author = "Meade, Nicholas  and
      Poole-Dayan, Elinor  and
      Reddy, Siva",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.132",
    doi = "10.18653/v1/2022.acl-long.132",
    pages = "1878--1898",
    abstract = "Recent work has shown pre-trained language models capture social biases from the large amounts of text they are trained on. This has attracted attention to developing techniques that mitigate such biases. In this work, we perform an empirical survey of five recently proposed bias mitigation techniques: Counterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias, and SentenceDebias. We quantify the effectiveness of each technique using three intrinsic bias benchmarks while also measuring the impact of these techniques on a model{'}s language modeling ability, as well as its performance on downstream NLU tasks. We experimentally find that: (1) Self-Debias is the strongest debiasing technique, obtaining improved scores on all bias benchmarks; (2) Current debiasing techniques perform less consistently when mitigating non-gender biases; And (3) improvements on bias benchmarks such as StereoSet and CrowS-Pairs by using debiasing strategies are often accompanied by a decrease in language modeling ability, making it difficult to determine whether the bias mitigation was effective.",
      selected={true},
}

@inproceedings{NEURIPS2023_1a675d80,
 author = {Krojer, Benno and Poole-Dayan, Elinor and Voleti, Vikram and Pal, Chris and Reddy, Siva},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {8385--8405},
 publisher = {Curran Associates, Inc.},
 title = {Are Diffusion Models Vision-And-Language Reasoners?},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/1a675d804f50509b8e21d0d3ca709d03-Paper-Conference.pdf},
 volume = {36},
 year = {2023},
selected={true},
}
@misc{pooledayan2024llmtargetedunderperformancedisproportionately,
      title={LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users}, 
      author={Elinor Poole-Dayan and Deb Roy and Jad Kabbara},
      year={2024},
      eprint={2406.17737},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17737}, 
      selected={true},
}

@misc{fulay2024relationshiptruthpoliticalbias,
      title={On the Relationship between Truth and Political Bias in Language Models}, 
      author={Suyash Fulay and William Brannon and Shrestha Mohanty and Cassandra Overney and Elinor Poole-Dayan and Deb Roy and Jad Kabbara},
      year={2024},
      eprint={2409.05283},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.05283}, 
      selected={true},
}